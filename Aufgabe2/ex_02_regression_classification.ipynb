{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6aa89259c39a436186eb4cb658643603",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "id": "902b04ab",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1ae9507ed8fbc70992828fe876cb325",
     "grade": false,
     "grade_id": "cell-b4a5fabbdbb97f8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Grundlagen der K√ºnstlichen Intelligenz - Wintersemester 2025/26\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a3b8c9afea2c477b90e8c34058adef5d",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "id": "4ceec16e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d7c04e9848b1e6e0c905b569369213b",
     "grade": false,
     "grade_id": "cell-557b63afe58adf20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# √úbung 2: Regression und Klassifikation mit linearen Modellen\n",
    "\n",
    "---\n",
    "\n",
    "> **Grundlagen der k√ºnstlichen Intelligenz** im Wintersemester 2025/2026\n",
    ">\n",
    "> - Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> - T.T.-Prof. Peer Nowack, peer.nowack@kit.edu\n",
    "> \n",
    "> √úbungsleiter f√ºr die aktuelle √úbung: Jonas Teufel, jonas.teufel@kit.edu\n",
    "> \n",
    "> ‚ö†Ô∏è Bei allgemeinen Fragen zu Aufgabenstellungen etc. bitte im Ilias Forum posten, sodass wir diese Fragen nur ein Mal f√ºr alle Studierenden beantworten k√∂nnen. E-Mail an den √úbungsleiter bitte nur f√ºr individuelle Fragen, deren Beantwortung nicht f√ºr alle Studierenden relevant ist.\n",
    "\n",
    "---\n",
    "\n",
    "- **Wir nutzen ein automatisiertes Grading System zur Bewertung der Jupyter Notebooks (siehe unten f√ºr Details)**\n",
    "- **Bitte ladet dieses √úbungsblatt daher bei Ilias als Abgabe hoch, auch wenn ihr es nur teilweise (oder gar nicht!) bearbeitet habt.**\n",
    "- **Auf diese Weise k√∂nnt ihr technische Probleme beim Grading finden und wir k√∂nnen sie gemeinsam in der ersten Saal√ºbung l√∂sen.**\n",
    "- **Ab dem zweiten √úbungsblatt erwarten wir, dass die technischen Probleme gel√∂st sind.**\n",
    "- **Nutzt daher bitte diese M√∂glichkeit!**\n",
    "\n",
    "### √úbungsteam\n",
    "\n",
    "- Mozhgan Amiramjadi, mozhgan.amjadi@kit.edu\n",
    "- Lina Rennstich, lina.rennstich@kit.edu\n",
    "- Ulrich Oberhofer, ulrich.oberhofer@kit.edu\n",
    "- Laura Ruple, laura.ruple@kit.edu\n",
    "- Henrik Schopmans, henrik.schopmans@kit.edu\n",
    "- Jonas Teufel, jonas.teufel@kit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b0f43b908917478f8084470fd0648fa4",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3440b92b51b5177b8871d8d9f9d21e41",
     "grade": false,
     "grade_id": "cell-a5054117b5762652",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Gruppenabgabe\n",
    "\n",
    "Die √úbungsbl√§tter k√∂nnen in Gruppen von bis zu **3 Studierenden** abgegeben werden. **Jede Person aus der Gruppe muss die finale Version der Abgabe √ºber Ilias hochladen**, es gen√ºgt nicht, dass nur eine Person aus der Gruppe dies tut. Es ist prinzipiell m√∂glich, im Laufe des Semesters sich einer neuen Gruppe anzuschlie√üen, sollte sich die eigene Gruppe vorzeitig aufl√∂sen. Generell muss jede Gruppe ihre eigene L√∂sung hochladen, wir werden die Abgaben auf Duplikate √ºberpr√ºfen.\n",
    "\n",
    "Die Gruppen werden automatisch erfasst, **gebt deshalb die u-K√ºrzel eurer Gruppenmitglieder in die folgende Zelle ein.** Falls eure Gruppe nur aus 2 Studierenden besteht, oder ihr alleine abgibt, lasst die verbleibenden Felder frei. Hier ein Beispiel f√ºr eine Gruppe bestehend aus uabcd und uefgh:\n",
    "\n",
    "_U-K√ºrzel der Gruppenmitglieder:_\n",
    "\n",
    "_Mitglied 1: uabcd_\n",
    "\n",
    "_Mitglied 2: uefgh_\n",
    "\n",
    "_Mitglied 3:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c1518d7e12a144eaa103742f0ff3478a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "U-K√ºrzel der Gruppenmitglieder:\n",
    "\n",
    "Mitglied 1:\n",
    "\n",
    "Mitglied 2:\n",
    "\n",
    "Mitglied 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1bd42710e7b847b48d1e98956601c816",
    "deepnote_cell_type": "markdown",
    "deletable": false,
    "editable": false,
    "id": "4617191b",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3dda27481ecb38d3bb8fed4ee9b53f46",
     "grade": false,
     "grade_id": "cell-f4cd01f4946bdbe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Auto-grading\n",
    "\n",
    "Wir nutzen ein auto-grading System, welches eure abgegebenen Jupyter Notebooks automatisch analysiert und √ºber\n",
    "hidden tests auf Richtigkeit pr√ºft. √úber diese Tests werden die Punkte bestimmt, die ihr f√ºr das √úbungsblatt erhaltet.\n",
    "\n",
    "Damit das auto-grading reibungslos funktioniert bitte folgende Dinge beachten:\n",
    "\n",
    "- Notebook muss Dateinamen \"ex_02_regression_classification.ipynb\" haben\n",
    "- PDF und Jupyter notebook einzeln im Ilias hochladen (nicht als Zip!)\n",
    "- Vor dem Abgeben eines Notebooks bitte testen, dass alles von vorne bis hinten ohne Fehler durchl√§uft.\n",
    "- Zellen, welche mit \"##### DO NOT CHANGE #####\" markiert sind d√ºrfen weder gel√∂scht noch bearbeitet werden\n",
    "- Eure L√∂sung muss in die richtige Zelle (markiert mit \"# YOUR CODE HERE\") eingetragen werden.\n",
    "  - (dabei nat√ºrlich den NotImplementedError l√∂schen!)\n",
    "- Es gibt potentiell scheinbar leere Zellen, die auch mit \"\" markiert sind. Auch diese d√ºrfen nicht bearbeitet oder gel√∂scht werden.\n",
    "  - Falls dies doch gemacht wird, dann wird das automatische Grading nicht funktionieren und ihr erhaltet keine Punkte.\n",
    "  - Wir werden hier strikt handeln und keine Ausnahmen machen, falls jemand doch Zellen ver√§ndert, die eindeutig als readonly markiert sind!\n",
    "- Die Jupyter Notebooks haben inline Tests (f√ºr euch sichtbar), welche euer Ergebnis auf grobe Richtigkeit √ºberpr√ºfen.\n",
    "  - Diese sind prim√§r f√ºr euch, um Fehler zu erkennen und zu korrigieren.\n",
    "  - Die inline Tests, die ihr im Notebook sehen k√∂nnt, sind allerdings nicht die Tests welche f√ºr das Grading verwendet werden!\n",
    "  - Die inline Tests sind eine notwendige aber keine hinreichende Bedingung, um beim Grading der Aufgabe Punkte zu erhalten!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d0f1c17c2220491b893617a829647714",
    "deepnote_cell_type": "code",
    "deletable": false,
    "editable": false,
    "execution_context_id": "5a1103c4-0842-497c-951b-69d5a37cd3e1",
    "execution_millis": 2,
    "execution_start": 1730320171073,
    "id": "6656dcf6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4a240dd15632368034f181e9f1af9b2",
     "grade": false,
     "grade_id": "ro-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "source_hash": "9b244cd5"
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    ")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "def nextcloud_download(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the *content* of a file from a nextcloud server.\n",
    "    \n",
    "    :param url: the absolute URL of the file on the nextcloud server\n",
    "    \n",
    "    :returns: the string content of the file\n",
    "    \"\"\"\n",
    "    if not url.endswith('/download'):\n",
    "        url += '/download'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    content = response.content.decode('utf-8')\n",
    "    \n",
    "    return content\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cecf919f038dbc5f9e5126e1a9a09176",
     "grade": false,
     "grade_id": "cell-285cdaf482decc1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **2.1** $\\cdot$ *Regression*\n",
    "\n",
    "**Regression.** In diesem ersten Teil der Aufgabe befassen wir uns mit der Regressionsaufgabe - d.h. der Suche nach einer linearen Funktion welche eine gegebene Funktion $f: \\mathbb{R}^N \\rightarrow \\mathbb{R}, \\mathbf{x} \\mapsto y$ so gut wie m√∂glich approximiert. Im Normalfall haben wir dabei keinen Zugang zur analytischen Form dieser Funktion, sondern beziehen unser einziges Wissen von einem Datensatz bestehend aus konkreten *Samples* dieser Funktion. Wir k√∂nnen diese Samples nutzen im ein *Modell* der Funktion zu erstellen, welches diese hoffentlich bestm√∂glich ann√§hert.\n",
    "\n",
    "**Train-Test Aufteilung.** Das Ziel ist also eine solche Funktion $\\hat{f}: \\mathbb{R}^N \\rightarrow \\mathbb{R}, \\mathbf{x} \\mapsto \\hat{y}$ zu finden welche den (quadratischen) Fehler zur tats√§chlichen Funktion minimiert:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{x} \\in \\mathcal{X}} \\; (\\hat{f}(\\mathbf{x}) - f(\\mathbf{x}))^2\n",
    "$$\n",
    "\n",
    "Da wir $f(x)$ aber nicht an beliebiger Stelle evaluieren k√∂nnen, geschieht diese Minimierung in der Praxis nur √ºber eine bekannte und endliche Menge an  Eingabewerten $\\mathcal{X}$. Nutzt man hierf√ºr ein ausreichend komplexes Modell w√§re es m√∂glich f√ºr beliebig gro√üe Datenmenge einen Fehler von 0 zu erreichen (man Stelle sich zum Beispiel einen Lookup Table bzw. eine lineare Interpolation √ºber alle bekannten Punkte vor). Ein solches Modell w√§re aber h√∂chstwahrscheinlich nicht zielf√ºhrend um den Funktionswert von zuk√ºnftigen unbekannten Punkten vorherzusagen, da jeglicher Einfluss von Messrauschen etc. in ein solches Modell miteinflie√üt. Daher ben√∂tigt man eine sinnvollere M√∂glichkeit die Eignung eines Modells zu bewerten als den direkten Approximations-Fehler zu minimieren. In der Praxis erreicht man dies indem man die vorhandenen Daten aufteilt in einen Trainings- und einen Testdatensatz. Die Optimierung der Modellparameter findet dann ausschlie√ülich auf den Trainingsdaten statt. Anschlie√üend wird die Qualit√§t des Modells √ºber den Approximations-Fehler auf den Test Daten bewertet. Die Argumentation ist folgende: Nur wenn das Modell durch die Trainingsdaten die *wahre Funktion* approximiert, sollte es auch dementsprechend gute Vorhersagen f√ºr die Testdatenpunkte liefern - auch ohne explizit auf diesen optimiert worden zu sein.\n",
    "\n",
    "**Beispiel Funktion.** Die nachfolgende Zelle definiert zun√§chst eine beispielhafte Funktion welche im Folgenden als *wahre Funktion* zu Grunde gelegt wird. Daraufhin erstellen wir einen Trainings- und Testdatensatz indem wir konkrete Punkte von dieser Funktion sampeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4413acea123ce754c3e543b08a849fef",
     "grade": false,
     "grade_id": "cell-b81b2845151d778d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "def true_function_2d(\n",
    "    t: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The true function to be approximated. Takes as input a 2D array of shape\n",
    "    (N, 2) and returns the function value of shape (N, 1).\n",
    "    \n",
    "    Parameters:\n",
    "        t : np.ndarray\n",
    "            Input array of shape (..., 2) containing x and y coordinates.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray\n",
    "            Function values of shape (..., 1) computed from the input coordinates.\n",
    "    \"\"\"    \n",
    "    x = t[..., 0]\n",
    "    y = t[..., 1]\n",
    "    \n",
    "    result = (\n",
    "        0.5 * x**4 - 1.5 * x**2 + 2 * x +\n",
    "        3 * (y + x) - 0.5 * (x + y)**2 +\n",
    "        4\n",
    "    )\n",
    "    # Return with shape (..., 1) for consistency with predict_regressor output\n",
    "    return result[..., np.newaxis]\n",
    "    \n",
    "# --- generating a dataset ---\n",
    "\n",
    "def sample_dataset_2d(\n",
    "    n_samples: int, \n",
    "    noise_std: float = 1.0, \n",
    "    random_state: int = 42, \n",
    "    x_range: tuple = (-2, 2)\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Creates explicit samples of the `true_function_2d` by sampling uniformly within the\n",
    "    given input value range `x_range` and adding Gaussian noise with standard deviation\n",
    "    `noise_std` to the function values to emulate measurement noise.\n",
    "    \n",
    "    Parameters:\n",
    "        n_samples : int\n",
    "            Number of samples to generate.\n",
    "        noise_std : float\n",
    "            Standard deviation of the Gaussian noise to add to function values.\n",
    "        random_state : int\n",
    "            Random seed for reproducibility.\n",
    "        x_range : tuple\n",
    "            Range (min, max) for uniformly sampling input values.\n",
    "    \n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]\n",
    "            A tuple (x, y) where `x` is the input data of shape (n_samples, 2) and\n",
    "            `y` are the corresponding noisy function values of shape (n_samples,).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = rng.uniform(x_range[0], x_range[1], size=(n_samples, 2))\n",
    "    # true_function_2d now returns (n_samples, 1), so we need to flatten for consistency\n",
    "    y = true_function_2d(x).ravel() + rng.normal(0, noise_std, size=n_samples)\n",
    "    return x, y\n",
    "\n",
    "# We generate a training and a test dataset\n",
    "x_train_2d, y_train_2d = sample_dataset_2d(100, noise_std=0.5, random_state=0)\n",
    "x_test_2d, y_test_2d = sample_dataset_2d(100, noise_std=0.5, random_state=1)\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db5e9e131f61718458dbd1e17599bc60",
     "grade": false,
     "grade_id": "cell-6eb2287729073a98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä Visualisierung.** Diese Zelle visualisiert die gegebene und zu approximierende Funktion. Die Wireframe-Darstellung sowie der projizierte Contour-Plot zeigen die Funktionswerte der wahren Funktion. Die blauen und orangen Punkte zeigen die von dieser Funktion gesampleten Trainings- und Testdatenpunkte, welche sp√§ter f√ºr das Fitting und die Evaluation eines Regressionsmodells verwendet werden k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5e3229e967284646de54985e7706371",
     "grade": false,
     "grade_id": "cell-43d1aa08ab2df090",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- plotting the 2d function ---\n",
    "\n",
    "val_min, val_max = -2, 2\n",
    "\n",
    "# Create a grid for plotting the 2D function\n",
    "x_grid = np.linspace(val_min, val_max, 100)\n",
    "y_grid = np.linspace(val_min, val_max, 100)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Create input array for the true_function_2d\n",
    "grid_points = np.stack([X_grid, Y_grid], axis=-1)\n",
    "\n",
    "# Evaluate the function on the grid\n",
    "Z = true_function_2d(grid_points)\n",
    "\n",
    "# Create a 3D plot with surface and 2D projection\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D surface as wireframe\n",
    "wireframe = ax.plot_wireframe(X_grid, Y_grid, Z.squeeze(), alpha=0.6, color='black', linewidth=0.75, label='True Function Surface')\n",
    "\n",
    "# Create the 2D heatmap projection at the bottom\n",
    "# Get the z-limits to place the projection at the bottom\n",
    "z_min = np.min(Z)\n",
    "z_max = np.max(Z)\n",
    "z_offset = z_min - (z_max - z_min) * 0.01  # Place projection slightly below minimum\n",
    "\n",
    "# Plot the contour/heatmap at the bottom\n",
    "contour = ax.contourf(X_grid, Y_grid, Z.squeeze(), levels=20, zdir='z', offset=z_offset, cmap='magma', alpha=0.8)\n",
    "\n",
    "# Plot train and test data as scatter points\n",
    "ax.scatter(x_train_2d[:, 0], x_train_2d[:, 1], y_train_2d, c='blue', s=20, alpha=1., label='Train Data', zorder=100)\n",
    "ax.scatter(x_test_2d[:, 0], x_test_2d[:, 1], y_test_2d, c='orange', s=20, alpha=1., label='Test Data', zorder=100)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(contour, ax=ax, shrink=0.5, aspect=20, label='Function Value')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f(x, y)')\n",
    "ax.set_title('2D Function Visualization', fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust the viewing angle for better visualization\n",
    "ax.view_init(elev=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b15a1394e6d65091d70fda8e59864c8a",
     "grade": false,
     "grade_id": "cell-a690d688745b49d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.1.1** $\\cdot$ *Grundlagen der Linearen Regression*\n",
    "\n",
    "Im Folgenden wollen wir eine linear Regression selbst implementieren. F√ºr ein lineares Regressions Modell suchen wir nach einem Gewichtsvektor $\\mathbf{w}$ welcher mit den Eingangsdaten $\\mathbf{x}$ multipliziert die gesuchte Funktion $y = f(\\mathbf{x})$ approximiert:\n",
    "\n",
    "$$\n",
    "y_{pred} = \\mathbf{w} \\cdot \\begin{pmatrix}\n",
    "\\mathbf{x} \\\\ 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Durch eine explizite Optimierung der Summed Squared Error (SSE) finden wir eine analytische L√∂sung f√ºr den gesuchten Gewichtsvektor $\\mathbf{w}$. Diesen k√∂nnen wir n√§mlich - wie aus der Vorlesung bekannt - √ºber eine Pseudo-Inverse der Trainingsdaten $\\mathbf{X}$ multipliziert mit den korrespondierenden Funktionswerten $\\mathbf{y}$ bestimmen:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &= \\mathbf{X}^{\\dagger} \\cdot \\mathbf{y} \\\\\n",
    "\\mathbf{w} &= (\\mathbf{X}^T \\mathbf{X})^{-1}\\mathbf{X}^T \\cdot \\mathbf{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.1 (2 Punkte).</strong> Implementiere die unten stehende Funktionen <code>fit_regressor</code>. Diese Funktion soll einen Vektor <code>x</code> an Trainingsdaten und deren korrespondierende Funktionswerte <code>y</code> als Funktionswerte entgegennehmen und den entsprechenden Gewichtsvektor zur√ºckgeben. <em>Hinweis 1: </em> Der berechnete Gewichtsvektor soll auch ein Gewicht f√ºr den konstanten Bias Term enthalten! <em>Hinweis 2: </em> Stelle sicher dass die Funktion mit Daten verschiedener Dimensionalit√§t (verschiedene Anzahl an Eingabewerten x) umgehen kann! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf47b951ce892bb331d8cc0bec6a661f",
     "grade": false,
     "grade_id": "cell-303b8b2aabbdf551",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_regressor(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fit a linear regression model to the training data `x` of shape (n_samples, n_features)\n",
    "    and y of shape (n_samples, 1) using the ordinary least squares method.\n",
    "    Return the weight vector `w` of shape (n_features + 1, 1) including the bias term.\n",
    "    \n",
    "    Parameters:\n",
    "        x : np.ndarray\n",
    "            Input features of shape (n_samples, n_features).\n",
    "        y : np.ndarray\n",
    "            Target values of shape (n_samples, 1).\n",
    "        \n",
    "    Returns:\n",
    "        w : np.ndarray\n",
    "            Weight vector of shape (n_features + 1, 1) including the bias term.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efe31c902e0b6d479fec2598fa92e3aa",
     "grade": true,
     "grade_id": "task-2-1-fit-reg",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-1-fit-reg - possible points: 2\n",
    "\n",
    "# --- testing output shape for 2D function ---\n",
    "x_test_1 = np.array([[0, 1], [1, 1], [2, 1], [3, 1], [0, 3]])\n",
    "y_test_1 = np.array([[1], [2], [3], [4], [2]])\n",
    "w_test_1 = fit_regressor(x_test_1, y_test_1)\n",
    "print('w_test_1', w_test_1)\n",
    "assert isinstance(w_test_1, np.ndarray)\n",
    "assert w_test_1.shape == (3, 1)\n",
    "\n",
    "# --- testing output shape for 1D function ---\n",
    "x_test_2 = np.array([[0], [1], [2], [3], [4]])\n",
    "y_test_2 = np.array([[1], [2], [3], [4], [2]])\n",
    "w_test_2 = fit_regressor(x_test_2, y_test_2)\n",
    "print('w_test_2', w_test_2)\n",
    "assert isinstance(w_test_2, np.ndarray)\n",
    "assert w_test_2.shape == (2, 1)\n",
    "\n",
    "# --- hidden tests ---\n",
    "# The hidden tests will check for the correctness of the approximation with some sample\n",
    "# data\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76af62d5018b563485419c292497f8f9",
     "grade": false,
     "grade_id": "cell-97bc42545a06eb9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.2 (2 Punkte).</strong> Implementiere die unten stehende Funktion <code>predict_regressor</code>. Diese Funktion soll einen Vektor <code>x</code> an Eingangsdaten und eine zuvor berechneten Gewichtsvektor <code>w</code> entgegennehmen und die approximierten Funktionswerte <code>y_pred</code> zur√ºckgeben. <em>Hinweis: </em> Stelle sicher dass die Funktion mit Daten verschiedener Dimensionalit√§t (verschiedene Anzahl an Eingabewerten x) umgehen kann! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e224579a471c108c57393adf8eeefd16",
     "grade": false,
     "grade_id": "cell-e243c851004bcf89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_regressor(x: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict the target values for the input data `x` of shape (n_samples, n_features) \n",
    "    using the weight vector `w` of shape (n_features + 1, 1).\n",
    "\n",
    "    Parameters:\n",
    "        x : np.ndarray\n",
    "            Input features of shape (n_samples, n_features), \n",
    "            which *do not include* the bias term!\n",
    "        w : np.ndarray\n",
    "            Weight vector of shape (n_features + 1, 1) including the bias term.\n",
    "    \n",
    "    Returns:\n",
    "        y_pred : np.ndarray\n",
    "            Predicted target values of shape (n_samples, 1).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "774cdfa826c8528f56e6710fb5bb6946",
     "grade": true,
     "grade_id": "task-2-2-predict-reg",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-2-predict-reg - possible points: 2\n",
    "\n",
    "# --- testing output shape for 2D function ---\n",
    "x_test_1 = np.array([[0, 1], [1, 1], [2, 1], [3, 1], [0, 3]])\n",
    "w_test_1 = np.array([[1], [2], [3]])\n",
    "y_pred_1 = predict_regressor(x_test_1, w_test_1)\n",
    "print('y_pred_1', y_pred_1)\n",
    "assert isinstance(y_pred_1, np.ndarray)\n",
    "assert y_pred_1.shape == (5, 1)\n",
    "\n",
    "# --- testing output shape for 1D function ---\n",
    "x_test_2 = np.array([[0], [1], [2], [3], [4]])\n",
    "w_test_2 = np.array([[1], [2]])\n",
    "y_pred_2 = predict_regressor(x_test_2, w_test_2)\n",
    "print('y_pred_2', y_pred_2)\n",
    "assert isinstance(y_pred_2, np.ndarray)\n",
    "assert y_pred_2.shape == (5, 1)\n",
    "\n",
    "# --- hidden tests ---\n",
    "# The hidden tests will check for the correctness of the approximation with some sample\n",
    "# data\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b791f54ff8ec3b4867f03e8ae344db71",
     "grade": false,
     "grade_id": "cell-eba681bd042a62de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Mit dieser Implementierung der linearen Regression k√∂nnen wir nun ein Modell f√ºr unsere initiale 2-dimensionale Funktion erstellen. Hierzu \"trainieren\" wird das Modell auf den gesampleten Trainingsdatenpunkten und evaluieren danach den Fehler auf den Trainings- und Testdatenpunkten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6791e7c6eebaf6ec79a07141aaf151",
     "grade": false,
     "grade_id": "cell-08b1322e90eb69e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "w_2d = fit_regressor(x_train_2d, y_train_2d)\n",
    "print('weights', w_2d)\n",
    "\n",
    "y_train_pred = predict_regressor(x_train_2d, w_2d)\n",
    "mse_train = mean_squared_error(y_train_2d, y_train_pred)\n",
    "print('MSE on train data:', mse_train)\n",
    "\n",
    "y_test_pred = predict_regressor(x_test_2d, w_2d)\n",
    "mse_test = mean_squared_error(y_test_2d, y_test_pred)\n",
    "print('MSE on test data:', mse_test)\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe0728fb2bee9702507b648d58471e49",
     "grade": false,
     "grade_id": "cell-8da9e43ce01d38c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä Visualisierung.** Der folgende Plot visualisiert die durch die lineare Regression approximierte Funktion (rote Wireframe) im Vergleich zur wahren Funktion (schwarze Wireframe). Der auf den Boden projizierte Contour-Plot zeigt auf wie gro√ü der Approximationsfehler an der korrespondierenden Stelle ist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77883a2293edca0cddfa42da50e76c8c",
     "grade": false,
     "grade_id": "cell-8367ba4d44381474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- plotting the error between prediction and true function ---\n",
    "\n",
    "# Use the same grid as in the original plot\n",
    "val_min, val_max = -2, 2\n",
    "x_grid = np.linspace(val_min, val_max, 100)\n",
    "y_grid = np.linspace(val_min, val_max, 100)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Create input array for the functions\n",
    "grid_points = np.stack([X_grid, Y_grid], axis=-1)\n",
    "\n",
    "# Calculate true function values\n",
    "Z_true = true_function_2d(grid_points).squeeze()  # Remove singleton dimension for plotting\n",
    "\n",
    "# Calculate predicted function values using the trained linear regression model\n",
    "grid_points_reshaped = grid_points.reshape(-1, 2)\n",
    "Z_pred = predict_regressor(grid_points_reshaped, w_2d).reshape(X_grid.shape)\n",
    "\n",
    "# Calculate error between true and predicted functions\n",
    "Z_error = np.abs(Z_true - Z_pred)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the true function as gray wireframe\n",
    "wireframe_true = ax.plot_wireframe(X_grid, Y_grid, Z_true, alpha=0.6, color='black', \n",
    "                                  linewidth=0.75, label='True Function Surface')\n",
    "\n",
    "# Plot the predicted function as red wireframe\n",
    "wireframe_pred = ax.plot_wireframe(X_grid, Y_grid, Z_pred, alpha=0.5, color='red', \n",
    "                                  linewidth=0.75, label='Predicted Function Surface')\n",
    "\n",
    "# Create the error projection at the bottom using viridis colormap\n",
    "z_min = np.min([np.min(Z_true), np.min(Z_pred)])\n",
    "z_max = np.max([np.max(Z_true), np.max(Z_pred)])\n",
    "z_offset = z_min - (z_max - z_min) * 0.05  # Place projection slightly below minimum\n",
    "\n",
    "# Plot the error contour/heatmap at the bottom\n",
    "contour = ax.contourf(X_grid, Y_grid, Z_error, levels=20, zdir='z', offset=z_offset, \n",
    "                     cmap='viridis', alpha=0.8)\n",
    "\n",
    "# Add a colorbar for the error\n",
    "cbar = fig.colorbar(contour, ax=ax, shrink=0.5, aspect=20, label='Error |True - Predicted|')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f(x, y)')\n",
    "ax.set_title('True vs Predicted 2D Function with Error Projection', fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Adjust the viewing angle for better visualization\n",
    "ax.view_init(elev=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ff0fc926151ad387c0784f045b8e5f6",
     "grade": false,
     "grade_id": "cell-e434ddeeef9a0047",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.1.2** $\\cdot$ *Nicht-Lineare Regression und Generalisierung*\n",
    "\n",
    "Im Folgenden besch√§ftigen wir uns mit der Polynom Regression als eine Erweiterung der linearen Regression. Hierzu definieren wir wieder eine wahre Funktion welche wir mit einem Modell approximieren wollen. Dieses Mal handelt es sich der Anschaulichkeit halber um eine 1-dimensionale Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32e847e94d030a818cc34f0f57991007",
     "grade": false,
     "grade_id": "cell-85c5f31e811ca09e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "def true_function_1d(x: float | np.ndarray) -> float | np.ndarray:\n",
    "    \"\"\"\n",
    "    A polynomial function to be approximated by regression models.\n",
    "    Works with both scalar inputs and numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "        x : float or np.ndarray\n",
    "            Input value(s). Can be a scalar or array of shape (N,).\n",
    "    \n",
    "    Returns:\n",
    "        float or np.ndarray\n",
    "            Function value(s) computed as 0.5*x^4 - 1.5*x^2 + 2*x + 3.\n",
    "            Returns same type as input (scalar returns scalar, array of shape (N,) returns array of shape (N,)).\n",
    "    \"\"\"\n",
    "    return 0.5*x**4 - 1.5 * x**2 + 2*x + 3\n",
    "\n",
    "\n",
    "# --- generating a dataset ---\n",
    "\n",
    "def generate_dataset_1d(\n",
    "    num_samples: int = 100,\n",
    "    noise_std: float = 0.5,\n",
    "    x_range: tuple = (-1.0, +1.0),\n",
    "    seed: int = 42,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates a dataset by sampling from `true_function_1d` and adding Gaussian noise.\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples : int\n",
    "            Number of data points to generate.\n",
    "        noise_std : float\n",
    "            Standard deviation of Gaussian noise to add to function values.\n",
    "        x_range : tuple\n",
    "            Range (min, max) from which to uniformly sample x values.\n",
    "        seed : int\n",
    "            Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]\n",
    "            A tuple (xs, ys_noisy) where `xs` contains the sampled x values and\n",
    "            `ys_noisy` contains the corresponding noisy function values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using a seeded RNG object will make sure that any subsequent random operations will be based on pseudo-random \n",
    "    # numbers which will look random but will be reproducible if the same seed is used again.\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    \n",
    "    # Then we sample a bunch of x values uniformly from the specified range and compute the corresponding true values \n",
    "    # using the true_function. \n",
    "    xs = rng.uniform(x_range[0], x_range[1], size=num_samples)\n",
    "    ys = true_function_1d(xs)\n",
    "    # To simulate real-world data, we add Gaussian noise to these true values.\n",
    "    ys_noisy = ys + rng.normal(0, noise_std, size=ys.shape)\n",
    "\n",
    "    return xs, ys_noisy\n",
    "\n",
    "\n",
    "X_MIN, X_MAX = -1.6, +1.6\n",
    "\n",
    "x_train_1d, y_train_1d = generate_dataset_1d(\n",
    "    num_samples=20, \n",
    "    noise_std=0.5, \n",
    "    seed=0, \n",
    "    x_range=(X_MIN, X_MAX)\n",
    ")\n",
    "x_test_1d, y_test_1d = generate_dataset_1d(\n",
    "    num_samples=20, \n",
    "    noise_std=0.5, \n",
    "    seed=1, \n",
    "    x_range=(X_MIN, X_MAX)\n",
    ")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6e523bb8c6aecf1bd7201a96d400694",
     "grade": false,
     "grade_id": "cell-81a2cd81a3464346",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä Visualisierung.** Der unten zu generierte Plot zeigt die wahre, zu approximierende Funktion gestrichelt im Hintergrund und die davon gesampleten Trainings- und Testdatenpunkte in blau bzw. orange. In diesem Fall gehen wir davon aus dass die Datenpunkte mit etwas mehr Messrauschen generiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f6f053c8682c0b0a1da92178aa04f70",
     "grade": false,
     "grade_id": "cell-14409821344e274a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "xs_true = np.linspace(X_MIN, X_MAX, 100)\n",
    "ys_true = true_function_1d(xs_true)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xs_true, ys_true, label=\"True Function\", color=\"gray\", ls='--')\n",
    "sns.scatterplot(x=x_train_1d, y=y_train_1d, label=\"Train Data\", color=\"blue\")\n",
    "sns.scatterplot(x=x_test_1d, y=y_test_1d, label=\"Test Data\", color=\"orange\")\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "\n",
    "plt.title('1D Function with Noisy Data', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36ad4d443d57d14c3dd8f875eb3013ef",
     "grade": false,
     "grade_id": "cell-30f0bb21940ccf19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Scikit Learn.** Zun√§chst wollen wir als Baseline wieder ein lineares Regressions Modell fitten. Hierzu k√∂nnten wir unsere bereits implementierte eigene Funktion verwenden. Viele grundlegende Funktionen des Machine Learning m√ºssen allerdings nicht immer wieder re-implementiert werden da sie schon in der `scikit-learn` Bibliothek enthalten sind, welche wir in diesem Fall benutzen wollen. Die Bibliothek stellt Implementationen f√ºr viele der g√§ngigen Machine Learning Modelle bereit, darunter auch lineare Regression, Decision Trees, Random Forests, Neural Networks und Vieles mehr.\n",
    "\n",
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.3 (1 Punkte).</strong> Initialisiere eine neue Instanz des <code>LinearRegression</code> Modells in der unten angegebenen Variable <code>model</code> und nutze die <code>fit</code> Funktion um das Modell auf den gegebenen Trainingsdaten zu fitten.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca39b4f6a3c920a70249787b4adc47ba",
     "grade": false,
     "grade_id": "cell-e3bab626bef4a9a5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model: LinearRegression = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4004c17ca84b2039916d8e53b030c60c",
     "grade": true,
     "grade_id": "task-2-3-sklearn-reg",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-3-sklearn-reg - possible points: 1\n",
    "\n",
    "# --- checking type ---\n",
    "assert model is not None, \"You have to initialize the model variable with a LinearRegression model and fit it on the training data.\"\n",
    "assert isinstance(model, LinearRegression), \"The model variable has to be of type LinearRegression.\"\n",
    "assert hasattr(model, \"coef_\"), \"The model has not been fitted yet. Please fit the model on the training data.\"\n",
    "\n",
    "# --- hidden tests ---\n",
    "# Checking if the model is fitted correctly by evaluating its performance on the test set\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca33797884f1ff1ececd977e49ef7b56",
     "grade": false,
     "grade_id": "cell-3b6ca2b96564064e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- model evaluation on test set ---\n",
    "# Evaluate the trained model on the test set\n",
    "ys_pred = model.predict(x_test_1d.reshape(-1, 1))\n",
    "mse_value = mean_squared_error(y_test_1d, ys_pred)\n",
    "print(f' * MSE on the test set: {mse_value:.4f}')\n",
    "\n",
    "# --- visualization preparation ---\n",
    "# Generate predictions for the full range to create smooth line\n",
    "x_true_1d = np.linspace(X_MIN, X_MAX, 100)\n",
    "ys_pred_line = model.predict(x_true_1d.reshape(-1, 1))\n",
    "\n",
    "# Calculate linear fit predictions for test data points (for vertical lines)\n",
    "ys_pred_test_points = model.predict(x_test_1d.reshape(-1, 1))\n",
    "\n",
    "# --- visualizing the linear fit ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training and test data points\n",
    "sns.scatterplot(x=x_train_1d, y=y_train_1d, label=\"Train Data\", color=\"blue\")\n",
    "sns.scatterplot(x=x_test_1d, y=y_test_1d, label=\"Test Data\", color=\"orange\")\n",
    "\n",
    "# Plot the linear fit line\n",
    "plt.plot(x_true_1d, ys_pred_line, label=\"Linear Fit\", color=\"black\")\n",
    "\n",
    "# Add vertical lines from test data points to linear fit\n",
    "for i, (x_test, y_test, y_pred_point) in enumerate(zip(x_test_1d, y_test_1d, ys_pred_test_points)):\n",
    "    plt.plot(\n",
    "        [x_test, x_test], \n",
    "        [y_test, y_pred_point], \n",
    "        color=\"gray\", \n",
    "        alpha=0.6, \n",
    "        linestyle=\"-\", \n",
    "        linewidth=1, \n",
    "        zorder=-10\n",
    "    )\n",
    "\n",
    "# Configure plot appearance\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(f\"True vs Predicted Function\\nTest MSE: {mse_value:.3f}\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "606192d0820dbff0c1213fed340c6ce6",
     "grade": false,
     "grade_id": "cell-b8dba7a4e5e668fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Polynom Regression.** Nun wollen wir anstelle einer linearen Funktion eine polynomielle Funktion fitten. Im eindimensionalen Fall wollen wir bei der linearen Regression zwei Parameter $c_0, c_1$ fitten:\n",
    "\n",
    "$$\n",
    "y = c_1 \\cdot x + c_0\n",
    "$$\n",
    "\n",
    "F√ºr den verallgemeinerten Fall der Polynom-Regression wollen wir stattdessen die $k$ Gewichte der polynomiellen Terme fitten:\n",
    "\n",
    "$$\n",
    "y = c_k \\cdot x^k + c_{k-1} \\cdot x^{k-1} + \\dots + c_1 \\cdot x + c_0\n",
    "$$\n",
    "\n",
    "Wie wir in der Vorlesung gelernt haben l√§sst sich dieser Fall auf die linear Regression zur√ºckf√ºhren indem wir einfach den Vektor der Eingangsdaten umdefinieren:\n",
    "\n",
    "$$\n",
    "\\phi = \\begin{pmatrix}\n",
    "x^k & x^{k-1} & \\dots & x & 1 \n",
    "\\end{pmatrix} \\\\\n",
    "y = \\mathbf{w} \\cdot \\phi\n",
    "$$\n",
    "\n",
    "und dann diese erweiterten Eingangsdaten nutzen um die Gewichte mit Hilfe der Pseudo-Inversen zu finden:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\cdot \\mathbf{y}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Scikit Learn.** Auch hierf√ºr stellt die `scikit-learn` Bibliothek bereits Funktionen bereit, welche wir im folgenden nutzen wollen. Als Startpunkt f√ºr eine Implementierung kann eine Internetsuche zu *\"Sklearn Polynom Regression\"* dienen.\n",
    "\n",
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.4 (4 Punkte).</strong> Implementiere die untenstehende Funktion <code>fit_polynomial_model</code>. Diese soll die Eingangsdaten <code>x</code>, die korrespondierenden Funktionswerte <code>y</code> und den gew√ºnschten Polynomgrad <code>degree</code> als Argumente akzeptieren. Basierend darauf soll eine bereits gefittete sklearn Instanz des Types <code>BaseEstimator</code> zur√ºckgegeben werden. <em>Hinweis:</em> BaseEstimator ist keine instanzierbare Klasse und dient nur als abstrakte Grundklasse von der alle spezifischen Modellklassen erben.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c907deea23a3a0cb7c4739aa78682125",
     "grade": false,
     "grade_id": "task-2-4-fit-pol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_model(\n",
    "    x: np.ndarray, \n",
    "    y: np.ndarray, \n",
    "    degree: int = 3,\n",
    ") -> sklearn.base.BaseEstimator:\n",
    "    \"\"\"\n",
    "    Fit a polynomial regression model of specified degree to the training data (x, y).\n",
    "    \n",
    "    Parameters:\n",
    "        x : np.ndarray\n",
    "            Input features of shape (n_samples, 1).\n",
    "        y : np.ndarray\n",
    "            Target values of shape (n_samples, 1).\n",
    "        degree : int\n",
    "            Degree of the polynomial features.\n",
    "    \n",
    "    Returns:\n",
    "        model : BaseEstimator\n",
    "            A scikit-learn estimator representing the fitted polynomial regression model.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8149d03fb79e4771944d996dfc09d31d",
     "grade": true,
     "grade_id": "task-2-4-fit-poly",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-4-fit-poly - possible points: 4\n",
    "\n",
    "# --- checking output type ---\n",
    "poly_model = fit_polynomial_model(x_train_1d, y_train_1d, degree=3)\n",
    "assert isinstance(poly_model, sklearn.base.BaseEstimator), \"The returned model should be an instance of sklearn BaseEstimator.\"\n",
    "assert hasattr(poly_model, \"predict\"), \"The returned model should have a predict method!\"\n",
    "\n",
    "# --- hidden tests ---\n",
    "# The hidden tests will check for the correctness of the polynomial regression model\n",
    "# for some sample data\n",
    "\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "998d76d04c5c1430f1b713c3f1945820",
     "grade": false,
     "grade_id": "cell-2563167f10d0cdfb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä Overfitting.** F√ºr die folgende Visualisierung fitten wir Polynomielle Modelle mit ansteigendem Grad, angefangen bei Grad 1. F√ºr jedes dieser Modelle bestimmen wir sowohl den Approximationsfehler auf den Trainingsdatenpunkten als auch auf den Testdatenpunkten und tragen diese in einem entsprechenden Diagramm ein. Die horizontale Achse dieses Diagramms zeigt die ansteigenden Polynomgrade und die vertikale Achse zeigt die entsprechenden Trainings- und Testfehler.\n",
    "\n",
    "In diesem Diagramm k√∂nnen wir einen typischen *Overfitting* Verlauf erkennen: Mit ansteigendem Polynomgrad sinkt der Fehler auf den Trainingsdatenpunkten weiter ab. Durch die steigende Komplexit√§t des Modells und die h√∂here Anzahl der freien Parameter hat das Modell mehr Kapazit√§t sich den gegebenen Trainingsdatenpunkten anzun√§hern. W√ºrden wir uns nur den Trainingsfehler ansehen, w√§ren wir verleitet ein Modell mit gr√∂√ütm√∂glichem Polynomgrad zu w√§hlen. Schauen wir uns allerdings den Testfehler an dann zeigt dieser genau den umgekehrten Verlauf: Der Testfehler steigt f√ºr h√∂here Polynomgrade immer weiter an. Die Polynome h√∂herer Ordnung k√∂nnen die gegebenen Trainingsdaten zwar besser abdecken hyperspezialisieren sich dabei aber auf das Messrauschen und entfernen sich in Realit√§t immer weiter von der wahren Funktion anstatt sich dieser weiter anzun√§hern.\n",
    "\n",
    "Im Allgemeinen geht man davon aus dass dieses Ph√§nomen des *Overfitting* vor allem dann auftritt wenn die Modellkapazit√§t (n√§herungsweise die Anzahl der frei lernbaren Parameter) die Komplexit√§t der zu lernenden Funktion drastisch √ºberschreitet - was h√§ufig der Fall ist wenn besonders wenig Trainingsdatenpunkte vorhanden sind. Als grobe Faustregel sollte man sich deshalb Gedanken um overfitting machen wenn die Anzahl der freien Parameter sehr gro√ü im Vergleich zur Anzahl der Verf√ºgbaren Trainingsdatenpunkte ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a4148a33143b9390e37817fcd2b9641",
     "grade": false,
     "grade_id": "cell-7003e7ca79b2993a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- fitting models of different degrees ---\n",
    "\n",
    "# Initialize lists to store MSE values for each degree\n",
    "degrees = range(1, 13)\n",
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "\n",
    "# Store fitted models for visualization\n",
    "fitted_models = {}\n",
    "\n",
    "# Fit polynomial models for degrees 1-12\n",
    "for degree in degrees:\n",
    "    # Create and fit polynomial model\n",
    "    model = fit_polynomial_model(x_train_1d, y_train_1d, degree=degree)\n",
    "\n",
    "    # Store the fitted model\n",
    "    fitted_models[degree] = model\n",
    "\n",
    "    # Predict on training and test data\n",
    "    train_pred = model.predict(x_train_1d.reshape(-1, 1))\n",
    "    test_pred = model.predict(x_test_1d.reshape(-1, 1))\n",
    "\n",
    "    # Calculate MSE using sklearn's mean_squared_error\n",
    "    train_mse = mean_squared_error(y_train_1d, train_pred)\n",
    "    test_mse = mean_squared_error(y_test_1d, test_pred)\n",
    "\n",
    "    # Store MSE values\n",
    "    train_mse_list.append(train_mse)\n",
    "    test_mse_list.append(test_mse)\n",
    "\n",
    "# Create two-panel plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Left panel: True function, data points, and polynomial fits\n",
    "# Generate dense x range for smooth plotting\n",
    "x_plot = np.linspace(X_MIN, X_MAX, 200)\n",
    "y_true_plot = true_function_1d(x_plot)\n",
    "\n",
    "# Plot true function\n",
    "#ax1.plot(x_plot, y_true_plot, 'k--', linewidth=2, label='True Function', alpha=0.8)\n",
    "\n",
    "# Plot training and test data\n",
    "ax1.scatter(x_train_1d, y_train_1d, color='blue', alpha=0.7, s=30, label='Train Data')\n",
    "ax1.scatter(x_test_1d, y_test_1d, color='orange', alpha=0.7, s=30, label='Test Data')\n",
    "\n",
    "# Plot polynomial fits for selected degrees\n",
    "selected_degrees = [1, 3, 5, 8, 12]\n",
    "colors = ['#000000', '#404040', '#808080', '#B0B0B0', '#E0E0E0']\n",
    "\n",
    "for i, degree in enumerate(selected_degrees):\n",
    "    model = fitted_models[degree]\n",
    "    y_pred_plot = model.predict(x_plot.reshape(-1, 1))\n",
    "    ax1.plot(x_plot, y_pred_plot, color=colors[i], linewidth=2,\n",
    "             label=f'Degree {degree}', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Data Points vs Polynomial Fits')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right panel: MSE curves\n",
    "ax2.plot(degrees, train_mse_list, 'b-o', label='Train MSE', color='blue')\n",
    "ax2.plot(degrees, test_mse_list, 'o-', label='Test MSE', color='orange')\n",
    "ax2.set_xlabel('Polynomial Degree')\n",
    "ax2.set_ylabel('Mean Squared Error')\n",
    "ax2.set_title('Training and Test MSE vs Polynomial Degree')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff06578f8093bea7ea253a6699ac3e47",
     "grade": false,
     "grade_id": "cell-9851767a8aceb83c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Out-of-Distribution Data.** Nun ist das zuvor beschriebene Overfitting nicht das einzige Ph√§nomen dessen man sich bewusst sein sollte. Einen weiterer wichtiger Effekt kommt durch eine systematische Verschiebung in der Trainingsdatenverteilung zu stande. In vielen Anwendungen des maschinellen Lernens werden Trainingsdaten gesammelt um ein Modell fitten zu k√∂nnen welches danach ein bestimmtes Problem l√∂sen soll. Als anschauliches Beispiel k√∂nnen wir ein Gesichtserkennungs-Modell betrachten: Ein solches Modell soll Gesichter auf Bildern erkennen um letztendlich zum Beispiel in einem √úberwachungssystem verwendet zu werden. Um dieses Modell zu trainieren haben wir einen hochqualitativen Datensatz an Studio-Bildern zusammengetragen, trainieren ein Modell und evaluieren es erfolgreich auf den zuvor aufgeteilten Testdatenpunkten. Trotzdem ist es sehr wahrscheinlich dass ein solches Modell unseren Erwartungen in der realen Anwendung nicht gerecht wird. Der Hauptgrund hierf√ºr ist dass die Bilder einer √úberwachungskamera sich in vielen Aspekten stark von professionellen Studio-Bildern unterscheiden - es liegen komplett andere Blickwinkel, Belichtungszust√§nde und Bildqualit√§ten vor. Letztendlich liegt eine gro√üe Diskrepanz zwischen der Trainingsdatenverteilung und der in Realit√§t erwarteten Datenverteilung vor - viele reale Samples sind *out-of-distribution (OOD)*.\n",
    "\n",
    "Im folgenden Abschnitt wollen wir diesen Aspekt genauer beleuchten. In den vorherigen Abschnitten wurde die gegebene wahre Funktion nur im Bereich $x \\in [-1.5, 1.5]$ evaluiert. Obwohl wir Trainings- und Testdatensatz getrennt haben, sind sie auf diesen Bereich beschr√§nkt. Im Folgenden wollen wir uns einen weiteren \"Datensatz\" ansehen welcher leicht au√üerhalb dieses Bereichs gesampled wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e12b23617128d791c120637814fe8b32",
     "grade": false,
     "grade_id": "cell-46d8d3e3b8e411b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "DELTA = 0.75\n",
    "\n",
    "xs_out_1d_left, ys_out_1d_left = generate_dataset_1d(num_samples=10, noise_std=0.75, seed=2, x_range=(X_MIN - DELTA, X_MIN))\n",
    "xs_out_1d_right, ys_out_1d_right = generate_dataset_1d(num_samples=10, noise_std=0.75, seed=3, x_range=(X_MAX, X_MAX + DELTA))\n",
    "\n",
    "xs_out_1d = np.concatenate([xs_out_1d_left, xs_out_1d_right])\n",
    "ys_out_1d = np.concatenate([ys_out_1d_left, ys_out_1d_right])\n",
    "\n",
    "# --- visualizing the true function outside of the training range ---\n",
    "\n",
    "xs_true = np.linspace(X_MIN - DELTA, X_MAX + DELTA, 200)\n",
    "ys_true = true_function_1d(xs_true)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlim(X_MIN - DELTA, X_MAX + DELTA)\n",
    "\n",
    "# Add background shading for out-of-distribution areas\n",
    "plt.axvline(x=X_MIN, color='gray', linestyle=':')\n",
    "plt.axvline(x=X_MAX, color='gray', linestyle=':')\n",
    "plt.axvspan(X_MIN - DELTA, X_MIN, alpha=0.1, color='gray', hatch='///', zorder=0)\n",
    "plt.axvspan(X_MAX, X_MAX + DELTA, alpha=0.1, color='gray', hatch='///', zorder=0)\n",
    "\n",
    "# Plotting the true function and data points\n",
    "plt.plot(xs_true, ys_true, label=\"True Function\", color=\"gray\", ls='--')\n",
    "sns.scatterplot(x=x_train_1d, y=y_train_1d, label=\"Train Data\", color=\"blue\")\n",
    "sns.scatterplot(x=x_test_1d, y=y_test_1d, label=\"Test Data\", color=\"orange\")\n",
    "sns.scatterplot(x=xs_out_1d, y=ys_out_1d, label=\"Out-of-Sample Data\", color=\"purple\", marker=\"o\")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4b909e67307cd990cf1a527d4344b3f",
     "grade": false,
     "grade_id": "cell-da105fcf03dbf463",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä OOD Approximations Fehler.** Die folgende Visualisierung zeigt den gleichen Verlauf wie zuvor, f√ºr welchen Modelle mit steigendem Polynomgrad gefitted werden um deren entsprechenden Trainings- und Testfehler zu ermitteln. Allerdings wird in diesem Fall zus√§tzlich der Fehler auf dem zuvor gezeigten OOD Datensatz ebenfalls ermittelt (lila).\n",
    "\n",
    "Zun√§chst k√∂nnen wir sehen dass der Fehler insgesamt *deutlich* h√∂her ist. D.h. in einer realen Anwendung, die potentiell nicht strikt auf diesen Bereich beschr√§nkt w√§re, h√§tte uns der niedrige Testfehler in die Irre gef√ºhrt. Noch wichtiger ist, dass wir einen anderen Verlauf √ºber die verschiedenen Polynomgrade beobachten k√∂nnen. F√ºr den Fall der OOD Daten kann man keine monotone Abnahme oder Zunahme mehr beobachten - viel mehr gibt es nun bestimmte Grade die Aufgrund der fortgef√ºhrten Form der Funktion deutlich besser geeignet sind als Andere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d800200b1597d9250c09ae5a70fc817",
     "grade": false,
     "grade_id": "cell-494740ce5315a390",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- fitting models of different degrees ---\n",
    "\n",
    "# Initialize lists to store MSE values for each degree\n",
    "degrees = range(1, 13)\n",
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "out_mse_list = []\n",
    "\n",
    "# Fit polynomial models for degrees 1-12\n",
    "for degree in degrees:\n",
    "    # Create and fit polynomial model\n",
    "    model = fit_polynomial_model(x_train_1d, y_train_1d, degree=degree)\n",
    "    \n",
    "    # Predict on training and test data\n",
    "    train_pred = model.predict(x_train_1d.reshape(-1, 1))\n",
    "    test_pred = model.predict(x_test_1d.reshape(-1, 1))\n",
    "    out_pred = model.predict(xs_out_1d.reshape(-1, 1))\n",
    "    \n",
    "    # Calculate MSE using sklearn's mean_squared_error\n",
    "    train_mse = mean_squared_error(y_train_1d, train_pred)\n",
    "    test_mse = mean_squared_error(y_test_1d, test_pred)\n",
    "    out_mse = mean_squared_error(ys_out_1d, out_pred)\n",
    "    \n",
    "    # Store MSE values\n",
    "    train_mse_list.append(train_mse)\n",
    "    test_mse_list.append(test_mse)\n",
    "    out_mse_list.append(out_mse)\n",
    "\n",
    "train_mse_list = np.array(train_mse_list)\n",
    "test_mse_list = np.array(test_mse_list)\n",
    "out_mse_list = np.array(out_mse_list)\n",
    "\n",
    "# Plot the results with dual y-axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot train and test MSE on left y-axis\n",
    "ax1.plot(degrees, train_mse_list, 'b-o', label='Train MSE', color='blue', ls='--')\n",
    "ax1.plot(degrees, test_mse_list, 'o-', label='Test MSE', color='orange', ls='--')\n",
    "ax1.set_xlabel('Polynomial Degree')\n",
    "ax1.set_ylabel('Train/Test MSE', color='black')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Create second y-axis for OOD MSE\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(degrees, out_mse_list, 'o-', label='OOD MSE', color='purple')\n",
    "ax2.set_ylabel('OOD MSE', color='purple')\n",
    "ax2.tick_params(axis='y', labelcolor='purple')\n",
    "ax2.set_ylim(0, 25)\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('MSE vs Polynomial Degree')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e736f2a141bc4c05ddab0fa800557a13",
     "grade": false,
     "grade_id": "cell-740515f44f0ff71e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.5 (1 Punkte).</strong> Welche Polynomordung sollte bestenfalls gew√§hlt werden - basierend auf den <em>out-of-distribution</em> Daten, welche in einem realistischen Anwendungsfall zu erwarten sind? Weise die Antwort als Integer der Variable <code>polynomial_degree</code> zu.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f16d0b67e61ed0ccc21be8991082b01",
     "grade": false,
     "grade_id": "sfdadfasdfasdf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "polynomial_degree: int = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f38077e65f06403fe598c3b60972cf3b",
     "grade": true,
     "grade_id": "task-2-5-poly-order",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-5-poly-order - possible points: 1\n",
    "\n",
    "assert isinstance(polynomial_degree, int), \"The polynomial_degree variable should be an integer.\"\n",
    "assert 1 <= polynomial_degree <= 12, \"The polynomial_degree should be between 1 and 12.\"\n",
    "\n",
    "# --- hidden tests ---\n",
    "# The hidden tests will check if the selected polynomial degree is correct\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e207af070a33af2e88c7b4c55fa353b",
     "grade": false,
     "grade_id": "cell-6ece7da7576a0541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Modell Evaluation.** Insgesamt soll dieses Beispiel verdeutlichen dass es sinnvoll ist sich Gedanken √ºber eine sinnvolle Modell Evaluation zu machen. Die zuf√§llige Aufteilung eines Datensatzes in Trainings- und Testdatenpunkte ist ein guter Anfang f√ºr eine Evaluation aber manchmal nicht ausreichend. Wie wir gesehen haben kann es sein dass ein zuf√§lliger Testdatensatz zu Schlussfolgerungen f√ºrht welche f√ºr eine reale Anwendung unter Umst√§nden nicht optimal sind. In solchen F√§llen kann man sich zum Beispiel √ºberlegen zus√§tzliche Daten f√ºr eine Evaluation aufzutreiben, welche n√§her an der realen Anwendung liegen. Alternativ kann man sich auch eine bessere Teilungsstrategie f√ºr einen vorhandenen Datensatz √ºberlegen anstatt zuf√§llig aufzuteilen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bea982c7b8c4fe7a999796a8b4dfef8a",
     "grade": false,
     "grade_id": "cell-2c635b0ed287ffa3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "# **2.2** $\\cdot$ *Klassifikation*\n",
    "\n",
    "Im n√§chsten Teil der Aufgabe wollen wir uns mit Klassifikationsproblemen besch√§ftigen. W√§hrend es bei der Regression darum geht die Funktionswerte einer kontinuierlichen Funktion $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ zu approximieren, geht es bei der Klassifikation um Funktionen mit einem diskreten Wertebereich, welcher nur eine endliche Zahl von m√∂glichen Funktionswerten annehmen kann, wie z.B. bei der bin√§ren Klassifikation $g: \\mathbb{R} \\rightarrow \\{0, 1\\}$.\n",
    "\n",
    "F√ºr die folgende Aufgabe nehmen wir das klassische Klassifikationsproblem des *Iris* Datensatzes unter die Lupe. Ziel des Datensatzes ist die Klassifikation der 3 verschiedenen Orchideen-Arten *iris setosa*, *iris versicolor* und *iris virginica* wie sie auch im Bild zu sehen sind. Hierzu wurde ein Datensatz aus verschiedenen Exemplaren dieser 3 Arten erstellt. Die Art wird dabei als zu approximierender Funktionswert $y$ herangezogen. Als Eingangsdaten werden jeweils die L√§ngen und Breiten der verschiedenen Blattstrukturen (petal, sepal) angesehen - was hei√üt dass insgesamt 4 Werte zur Klassifikation zur Verf√ºgung stehen. Das hei√üt es geht darum folgende Funktion zu approximieren.\n",
    "\n",
    "$$ \n",
    "h: \\mathbb{R}^4 \\rightarrow \\{setosa, versicolor, virginica\\}\n",
    "$$\n",
    "\n",
    "Um mit dieser Aufgabe zu beginnen laden wir uns zun√§chst den Datensatz herunter und vergewissern uns wie dieser aufgebaut ist.\n",
    "\n",
    "<img src=\"https://k3-production-bucket.s3.amazonaws.com/uploads/cD6ccKKMJJW8rENfe_51518iris%20img1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d72113a6223a4512dc06622a487909f0",
     "grade": false,
     "grade_id": "cell-93394346d80b2c59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "print(' * downloading the dataset from nextcloud ...')\n",
    "csv_content: str = nextcloud_download('https://bwsyncandshare.kit.edu/s/gXRcRWiza69qEjy')\n",
    "\n",
    "data_frame = pd.read_csv(io.StringIO(csv_content))\n",
    "print(f' * dataset with {len(data_frame)} entries')\n",
    "data_frame.head()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "552a6a45f9ac20678d06c31761444c3e",
     "grade": false,
     "grade_id": "cell-bb2180b6d95e29ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Den Datensatz, der momentan in der Form einer pandas `DataFrame` vorliegt, m√ºssen wir zun√§chst in die entsprechenden Matritzen $\\mathbf{X}$ und $\\mathbf{y}$ umwandeln. Nachdem wir die Daten umgewandelt haben, k√∂nnen wir den Datensatz auch in Trainings- und Testdatenpunkte aufteilen. Hierzu nutzen wir eine g√§ngige Aufteilung von 80 zu 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "138410bb1d7d32a2d1ab4b33e0a7e5f4",
     "grade": false,
     "grade_id": "cell-7e30e0331fbf72c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "x_cls = data_frame[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].to_numpy()\n",
    "# Note: y_cls will be a string array containing species names like 'Iris-setosa', 'Iris-versicolor', etc.\n",
    "# Scikit-learn models can handle string labels directly - they automatically encode them internally\n",
    "# to numeric values during training. This is more convenient than manually converting to integers\n",
    "# or one-hot encoding beforehand.\n",
    "y_cls = data_frame[['Species']].to_numpy()\n",
    "\n",
    "x_train_cls, x_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    x_cls,\n",
    "    y_cls,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63a35ff21c5f2bebb9cd4b90b53301ec",
     "grade": false,
     "grade_id": "cell-5fe746d5c7a2c0ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.2.1** $\\cdot$ *Logistische Regression*\n",
    "\n",
    "Um das beschriebene Klassifikationsproblem zu l√∂sen wollen wir *logistische Regression* nutzen, welche ebenfalls in `scikit-learn` implementiert ist. W√§hrend lineare Regression kontinuierliche Werte vorhersagt, transformiert logistische Regression die Ausgabe einer linearen Funktion in eine Wahrscheinlichkeit zwischen 0 und 1. Dies macht sie besonders geeignet f√ºr Klassifikationsaufgaben.\n",
    "\n",
    "**Mathematische Grundlagen.** F√ºr die bin√§re Klassifikation nutzt logistische Regression die *Sigmoid-Funktion* (auch logistische Funktion genannt) um die Ausgabe einer linearen Funktion auf das Intervall $[0, 1]$ abzubilden:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "F√ºr eine Eingabe $\\mathbf{x}$ wird zun√§chst eine gewichtete Linearkombination berechnet $z = \\mathbf{w}^T \\mathbf{x} + b$ und anschlie√üend durch die Sigmoid-Funktion transformiert. Das Ergebnis kann als Wahrscheinlichkeit f√ºr die Klassenzugeh√∂rigkeit interpretiert werden:\n",
    "\n",
    "$$\n",
    "P(y=1 | \\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w}^T \\mathbf{x} + b)}}\n",
    "$$\n",
    "\n",
    "**Multi-Class Klassifikation.** F√ºr Probleme mit mehr als zwei Klassen - wie im Fall des Iris-Datensatzes mit drei verschiedenen Arten - wird logistische Regression auf mehrere Klassen erweitert. Ein g√§ngiger Ansatz ist die *Softmax-Regression* (auch multinomiale logistische Regression genannt), welche f√ºr jede Klasse $k$ eine Wahrscheinlichkeit berechnet:\n",
    "\n",
    "$$\n",
    "P(y=k | \\mathbf{x}) = \\frac{e^{\\mathbf{w}_k^T \\mathbf{x}}}{\\sum_{j=1}^{K} e^{\\mathbf{w}_j^T \\mathbf{x}}}\n",
    "$$\n",
    "\n",
    "Hierbei wird f√ºr jede der $K$ Klassen ein eigener Gewichtsvektor $\\mathbf{w}_k$ gelernt. Die Klasse mit der h√∂chsten Wahrscheinlichkeit wird als finale Vorhersage gew√§hlt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2509de0f97cd22e8570aa5bee1d5632c",
     "grade": false,
     "grade_id": "cell-97be2099a10c3393",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.6 (2 Punkte).</strong> Instanziere eine neue Instanz der <code>LogisticRegression</code> Klasse in der unten ausgewiesenen Variable <code>logistic_model</code> und fitte dieses auf den gegebenen Trainingsdaten. <em>Hinweis:</em> Die versteckten Tests pr√ºfen auf eine Mindestgenauigkeit von 70%. Daher kann es Sinn machen neben dem fitting des Modells auch die Testgenauigkeit ausgeben zu lassen um sicherzustellen dass die erwartete Genauigkeit erreicht wird.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb5d036ba745e2c8cc5f6f51cb563422",
     "grade": false,
     "grade_id": "cell-4e593836dafb8a6f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "logistic_model: LogisticRegression = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "253811a06b465d20ccd1c3eaf1b4a1d7",
     "grade": true,
     "grade_id": "task-2-6-cls-fit",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-6-cls-fit - possible points: 2\n",
    "\n",
    "# --- checking type ---\n",
    "assert logistic_model is not None, \"You have to initialize the logistic_model variable with a LogisticRegression model and fit it on the training data.\"\n",
    "assert isinstance(logistic_model, LogisticRegression), \"The logistic_model variable has to be of type LogisticRegression.\"\n",
    "assert hasattr(logistic_model, \"coef_\"), \"The model has not been fitted yet. Please fit the model on the training data.\"\n",
    "\n",
    "# --- hidden tests ---\n",
    "# Checking if the model is fitted correctly by evaluating its performance on the test set to\n",
    "# be at least 70% accuracy\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cab3e0144101b12e1560ec614c10f70f",
     "grade": false,
     "grade_id": "cell-ffc3bd6908566060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- evaluating the model on test set ---\n",
    "y_pred_cls = logistic_model.predict(x_test_cls)\n",
    "acc_value = accuracy_score(y_test_cls, y_pred_cls)\n",
    "print(f' * Accuracy on the test set: {acc_value:.4f}')\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "843d2dd973fbc2aa1b74c104cabc5832",
     "grade": false,
     "grade_id": "cell-682c46dbce946088",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Confusion Matrix.** Eine *Confusion Matrix* (Verwechslungsmatrix) ist ein wichtiges Werkzeug zur Evaluation von Klassifikationsmodellen. Sie stellt die vorhergesagten Klassen den tats√§chlichen Klassen gegen√ºber: Elemente auf der Diagonalen repr√§sentieren korrekte Vorhersagen, w√§hrend Eintr√§ge au√üerhalb der Diagonalen Fehlklassifikationen darstellen.\n",
    "\n",
    "Unabh√§ngig von einem einzelnen Wert zur Modellgenauigkeit hilft eine solche Darstellung herauszufinden ob es bestimmte Kombinationen an Klassen gibt mit welchen das Problem besondere Probleme hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d89f539b5abcd4b5736868b57f459fa",
     "grade": false,
     "grade_id": "cell-016455cd8fb8e107",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "\n",
    "# --- creating confusion matrix ---\n",
    "conf_matrix = sklearn.metrics.confusion_matrix(y_test_cls, y_pred_cls)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis',\n",
    "            xticklabels=logistic_model.classes_,\n",
    "            yticklabels=logistic_model.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e566aa8fdd35efbc8d53e5156ba7c6dc",
     "grade": false,
     "grade_id": "cell-c958d2046bdc9c3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Decision Boundary.** Im n√§chsten Schritt w√ºrden wir gerne die *decision boundary* unseres Klassifikationsmodells visualisieren. Dies beschreibt ein Diagramm wobei die Achsen die Eingangswerte des Modells darstellen und die Bereiche zeigen, welche Klasse das Modell f√ºr jeden Punkt im Eingaberaum vorhersagen w√ºrde.\n",
    "\n",
    "**Dimensionalit√§tsreduktion.** F√ºr die gegebene Klassifikationsaufgabe ergibt sich dass Problem dass es sich um eine Funktion mit 4 Eingangswerten handelt und es notorisch schwer ist eine 4-dimensionale Funktion sinnvoll zu visualisieren. Eine M√∂glichkeit w√§re mehrere verschiedene 2D-Diagramme zu erstellen welche verschiedene paarweise Kombinationen der Eingangswerte abdecken. Eine andere M√∂glichkeit, welche in solchen F√§llen oft genutzt wird, ist eine *Dimensionalit√§tsreduktion* durchzuf√ºhren. Hierbei handelt es sich um eine Koordinatentransformation wobei die urspr√ºnglichen 4 Koordinaten auf lediglich 2 Variablen zur√ºckgef√ºhrt werden. Dabei wird jene Transformation gesucht welche zu einem m√∂glichst geringen Informationsverlust f√ºhrt.\n",
    "\n",
    "Eine h√§ufig verwendete Methode zur Dimensionalit√§tsreduktion ist die *Principle Component Analysis (PCA)*. Dies ist eine *lineare* Projektion der urspr√ºnglichen Koordinaten in einen niederdimensionalen Raum, wobei versucht wird die Varianz der Datenpunkte im reduzierten Raum zu maximieren.\n",
    "\n",
    "<img src=\"https://lh6.googleusercontent.com/proxy/5FoHrYaHli1iqNXZunq4wg9GrHhZJFfUlRYrBLpxOXLd1R7b9a8Hkk_uukWQbLTWlvmnq07l6yypWJXBZXDbdfbq5uOrc7e32I4AdrCezl4\">\n",
    "\n",
    "Im Folgenden f√ºrhen wir eine solche PCA durch um die Dimensionalit√§t der Eingangsdaten von 4 auf 2 (einfach visualisierbar) zu reduzieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b602a0898fc2ca8b9b8628dcb9e086a9",
     "grade": false,
     "grade_id": "cell-7001c89bd6d06784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "reducer = PCA(n_components=2)\n",
    "x_reduced = reducer.fit_transform(x_cls)\n",
    "print(f' * dimensionality reduced from {x_cls.shape[1]} to {x_reduced.shape[1]} dimensions')\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebe830ba69ced8d8057bc7d02e122f87",
     "grade": false,
     "grade_id": "cell-e9065ef2031e93ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce39b581d2c324408f0e658d70b0e4c0",
     "grade": false,
     "grade_id": "cell-874a1e7ba38413cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**üìä Decision Boundary.** Das unten gezeigte Diagramm stellt die Entscheidungsgrenze des zuvor trainierten logistischen Regressionsmodells dar. Hierbei werden zun√§chst die Datenpunkte des Testdatensatzes durch die PCA auf die transformierten Koordinaten projiziert und mit verschiedenen Farben im Diagramm eingetragen. Die S√§ttigung der Hintergrundfarbe zeigt die confidence des Klassifikationsmodells and der entsprechenden Stelle an. Volle Farbs√§ttigung impliziert eine 100%-ige Klassifikationswahrscheinlichkeit f√ºr die der Farbe entsprechende Klasse. Wei√üe Bereiche markieren die Entscheidungsgrenze zwischen zwei Klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d1300ab36ea671e0e66e4ba0cec516f",
     "grade": false,
     "grade_id": "cell-c74da1d6d64dffee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# --- plot the decision boundary based on PCA dimensions ---\n",
    "\n",
    "# Create a mesh grid in the 2D PCA space\n",
    "x_min, x_max = x_reduced[:, 0].min() - 0.5, x_reduced[:, 0].max() + 0.5\n",
    "y_min, y_max = x_reduced[:, 1].min() - 0.5, x_reduced[:, 1].max() + 0.5\n",
    "\n",
    "# Create a fine mesh grid for smooth decision boundary\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                     np.linspace(y_min, y_max, 300))\n",
    "\n",
    "# Transform grid points back to original 4D space using inverse PCA\n",
    "grid_points_2d = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_points_4d = reducer.inverse_transform(grid_points_2d)\n",
    "\n",
    "# Get decision probabilities for all classes from the logistic regression model\n",
    "decision_probs = logistic_model.predict_proba(grid_points_4d)\n",
    "\n",
    "# Define class colors as RGB values: pink, orange, aquamarine\n",
    "class_colors_rgb = np.array([\n",
    "    [1.0, 0.75, 0.8],    # hotpink\n",
    "    [1.0, 0.65, 0.0],    # orange  \n",
    "    [0.5, 1.0, 0.83]     # aquamarine\n",
    "])\n",
    "\n",
    "# Create color mixing function\n",
    "def create_multiclass_colors(probs, class_colors):\n",
    "    \"\"\"\n",
    "    Create RGB colors by mixing class colors based on probabilities.\n",
    "    Areas with uncertain predictions (equal probs) will be white.\n",
    "    Areas with high confidence will show saturated class colors.\n",
    "    \"\"\"\n",
    "    # Calculate confidence as deviation from uniform distribution\n",
    "    uniform_prob = 1.0 / probs.shape[1]  # 1/3 for 3 classes\n",
    "    max_prob = np.max(probs, axis=1)\n",
    "    confidence = (max_prob - uniform_prob) / (1.0 - uniform_prob)\n",
    "    \n",
    "    # Weight colors by probabilities\n",
    "    rgb_colors = np.dot(probs, class_colors)\n",
    "    \n",
    "    # Blend with white based on confidence\n",
    "    # Low confidence -> white, high confidence -> class color\n",
    "    white = np.array([1.0, 1.0, 1.0])\n",
    "    final_colors = confidence[:, np.newaxis] * rgb_colors + (1 - confidence[:, np.newaxis]) * white\n",
    "    \n",
    "    # Ensure values are in [0, 1] range\n",
    "    final_colors = np.clip(final_colors, 0, 1)\n",
    "    \n",
    "    return final_colors.reshape(xx.shape[0], xx.shape[1], 3)\n",
    "\n",
    "# Create the multi-class color map\n",
    "multiclass_colors = create_multiclass_colors(decision_probs, class_colors_rgb)\n",
    "\n",
    "# Calculate confidence for contour lines\n",
    "uniform_prob = 1.0 / 3\n",
    "max_probs = np.max(decision_probs, axis=1)\n",
    "confidence_grid = ((max_probs - uniform_prob) / (1.0 - uniform_prob)).reshape(xx.shape)\n",
    "\n",
    "# Transform test set to PCA space for plotting\n",
    "x_test_reduced = reducer.transform(x_test_cls)\n",
    "\n",
    "# Define class colors for scatter plot\n",
    "class_colors = ['hotpink', 'orange', 'aquamarine']\n",
    "class_names = logistic_model.classes_\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the multi-class decision boundary using imshow for the color mixing\n",
    "plt.imshow(multiclass_colors, extent=[x_min, x_max, y_min, y_max], \n",
    "           origin='lower', alpha=0.8, aspect='auto')\n",
    "\n",
    "# Add discrete confidence contour lines\n",
    "confidence_levels = [0.2, 0.4, 0.6, 0.8]\n",
    "contour_lines = plt.contour(xx, yy, confidence_grid, levels=confidence_levels, \n",
    "                           colors='gray', alpha=0.6, linewidths=1)\n",
    "plt.clabel(contour_lines, inline=True, fontsize=8, fmt='%.1f')\n",
    "\n",
    "# Plot the projected test set with custom colors\n",
    "for i, class_name in enumerate(class_names):\n",
    "    # Get indices for this class\n",
    "    class_mask = (y_test_cls.ravel() == class_name)\n",
    "    plt.scatter(x_test_reduced[class_mask, 0],\n",
    "               x_test_reduced[class_mask, 1],\n",
    "               c=class_colors[i],\n",
    "               s=80,\n",
    "               alpha=0.9,\n",
    "               edgecolors='black',\n",
    "               linewidth=1.5,\n",
    "               label=class_name,\n",
    "               zorder=5)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('First Principal Component', fontsize=12)\n",
    "plt.ylabel('Second Principal Component', fontsize=12)\n",
    "plt.title('Multi-Class Decision Boundary in PCA Space', \n",
    "          fontsize=14)\n",
    "\n",
    "# Create custom legend\n",
    "legend1 = plt.legend(title='Species', loc='upper right', fontsize=10)\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "# Add confidence legend\n",
    "from matplotlib.lines import Line2D\n",
    "confidence_legend_elements = [Line2D([0], [0], color='gray', alpha=0.6, linewidth=1, \n",
    "                                   label='Confidence contours')]\n",
    "legend2 = plt.legend(handles=confidence_legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "828c775b7edfb9115ec3a891a5a88757",
     "grade": false,
     "grade_id": "cell-8dab171f87e4a301",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div style=\"border: 1px solid #CEB037; border-radius: 3px; padding: 6px; background-color: #faf7e0ff; color: black;\">\n",
    "<strong>üõ†Ô∏è Aufgabe 2.8 (1 Bonuspunkt).</strong> Im obigen Plot sind die decision boundaries des logistischen Regressionsmodells dargestellt, welches gefitted wurde um das Iris-Klassifikationsproblem zu l√∂sen. Die Entscheidungsgrenzen erscheinen momentan als gerade Linien. Weise der unten stehenden Variable <code>answer</code> einen boolschen Wert zu um folgende Frage zu beantworten: W√§re es m√∂glich bei gleichem Modell (logistische Regression) und gleicher Projektion (PCA) aber bei beliebig anderen Daten gekr√ºmmte (nicht gerade) Entscheidungsgrenzen zu sehen?\n",
    "<em>Hinweis:</em> Bonuspunkteaufgaben tragen nicht zur Maximalpunkteanzahl eines √úbungsblattes bei.</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cae350f80480b401a91bffc50901bc0a",
     "grade": false,
     "grade_id": "cell-54f82cb56aed20ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# True -> curved decision boundaries would be possible\n",
    "# False -> decision boundaries will always be straight\n",
    "answer: bool = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "249482135c18b4b3896c32cd2c910946",
     "grade": true,
     "grade_id": "task-2-8-decision-bound",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### DO NOT CHANGE #####\n",
    "# ID: task-2-8-decision-bound - possible points: 1\n",
    "\n",
    "# --- hidden tests ---\n",
    "# The hidden tests will check if the answer is correct\n",
    "\n",
    "assert answer is not None, \"You have to set the answer variable to either True or False.\"\n",
    "assert isinstance(answer, bool), \"The answer variable should be a boolean (True or False).\"\n",
    "\n",
    "\n",
    "##### DO NOT CHANGE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "700c1e34ba051986b242112e57e96c5a",
     "grade": false,
     "grade_id": "cell-3cd470b244459394",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Zusammenfassung und Reflexion\n",
    "\n",
    "In diesem √úbungsblatt haben Sie sich mit den grundlegenden Konzepten der **Regression** und **Klassifikation** vertraut gemacht. Sie haben lineare Modelle von Grund auf implementiert, deren Grenzen kennengelernt und gelernt, wie man sie mit Hilfe von scikit-learn effizient einsetzt.\n",
    "\n",
    "**Was Sie gelernt haben:**\n",
    "\n",
    "- **Lineare Regression**: Implementierung der Ordinary Least Squares Methode √ºber die Pseudo-Inverse, um kontinuierliche Funktionen zu approximieren.\n",
    "- **Train-Test Aufteilung**: Die Bedeutung der Trennung von Trainings- und Testdaten zur Bewertung der Modellgeneralisierung.\n",
    "- **Overfitting**: Wie komplexere Modelle (h√∂here Polynomgrade) zu besserer Anpassung an Trainingsdaten f√ºhren k√∂nnen, aber gleichzeitig schlechtere Vorhersagen auf neuen Daten liefern.\n",
    "- **Out-of-Distribution Daten**: Die Herausforderung, dass Modelle auf Daten au√üerhalb des Trainingsbereichs oft schlecht performen, selbst wenn der Testfehler niedrig ist.\n",
    "- **Polynom-Regression**: Erweiterung linearer Modelle durch Transformation der Eingabefeatures, um nicht-lineare Funktionen zu approximieren.\n",
    "- **Logistische Regression**: Ein lineares Modell f√ºr Klassifikationsaufgaben, das Wahrscheinlichkeiten f√ºr Klassenzugeh√∂rigkeiten vorhersagt.\n",
    "- **Multi-Class Klassifikation**: Erweiterung der bin√§ren Klassifikation auf mehrere Klassen mittels Softmax-Regression.\n",
    "- **Dimensionalit√§tsreduktion**: Verwendung von PCA zur Visualisierung hochdimensionaler Entscheidungsgrenzen in 2D.\n",
    "\n",
    "**Wichtige Erkenntnisse:**\n",
    "\n",
    "1. **Modellkomplexit√§t vs. Generalisierung**: Ein Modell sollte komplex genug sein, um die zugrunde liegende Funktion zu erfassen, aber nicht so komplex, dass es Rauschen lernt.\n",
    "2. **Evaluation ist entscheidend**: Die Art und Weise, wie Sie Ihr Modell evaluieren (zuf√§llige Train-Test-Splits, OOD-Daten, Cross-Validation), hat gro√üen Einfluss darauf, wie gut Ihre Schlussfolgerungen f√ºr reale Anwendungen sind.\n",
    "\n",
    "Dies ist das Ende des √úbungsblattes. Bitte vergessen Sie nicht das Notebook vor der Abgabe einmal komplett von vorne durchlaufen zu lassen um auf m√∂gliche Fehler zu pr√ºfen. **Und denken sie insbesondere daran den handschriftlichen Teil der √úbung ebenfalls, in PDF Format, hochzuladen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd259050c7d05d4706ddc71c87094305",
     "grade": false,
     "grade_id": "cell-7161856a27784a86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "d98bf76200044b16a07679afbfe74dc6",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
